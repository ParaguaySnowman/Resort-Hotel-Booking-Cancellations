{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not yet run this neural network on a dataset that has been test/train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import to dataframe\n",
    "df = pd.read_csv('hotel_bookings.csv')\n",
    "\n",
    "#There were two hotels in the data set, we will examine only the resort hotel, for increased accuracy.\n",
    "df = df[df['hotel'] == 'Resort Hotel']\n",
    "\n",
    "#The dataset is quite large, and I am getting memory errors. I will split it randomnly.\n",
    " #df = df.sample(frac=0.05, random_state=13)\n",
    "\n",
    "#Dropping some data:\n",
    "df = df.dropna(subset=['country'])\n",
    "\n",
    "#Filling in some missing data:\n",
    "df['agent'] = df['agent'].fillna(536.0)\n",
    "df['company'] = df['company'].fillna(5.0)\n",
    "\n",
    "#Cleaning Data:\n",
    "\n",
    "#Getting Cancellation Frequencies for various variables:\n",
    "df['customer_cancel_score'] = np.round(np.where(df['is_repeated_guest'] > 0, df['previous_bookings_not_canceled']/(df['previous_bookings_not_canceled'] + df['previous_cancellations']), 0), 1)\n",
    "\n",
    "#Much of the data in this set is categorical, I will make useful numerical data out of it by calculating cancellation\n",
    "#fre3quencies for each value of these categorical variables.\n",
    "agent_df = pd.DataFrame(df[['is_canceled','agent']].groupby('agent', as_index=False).agg('mean'))\n",
    "company_df = pd.DataFrame(df[['is_canceled','company']].groupby('company', as_index=False).agg('mean'))\n",
    "country_df = pd.DataFrame(df[['is_canceled','country']].groupby('country', as_index=False).agg('mean'))\n",
    "\n",
    "agent_df = agent_df.rename(index=str, columns={\"is_canceled\": \"agent_cancel_score\"})\n",
    "company_df = company_df.rename(index=str, columns={\"is_canceled\": \"company_cancel_score\"})\n",
    "country_df = country_df.rename(index=str, columns={\"is_canceled\": \"country_cancel_score\"})\n",
    "\n",
    "df = pd.merge(df,agent_df,how='left',on=['agent'])\n",
    "df = pd.merge(df,company_df,how='left',on=['company'])\n",
    "df = pd.merge(df,country_df,how='left',on=['country'])\n",
    "\n",
    "distribution_channel_df = pd.DataFrame(df[['is_canceled','distribution_channel']].groupby('distribution_channel', as_index=False).agg('mean'))\n",
    "distribution_channel_df = distribution_channel_df.rename(index=str, columns={\"is_canceled\": \"distribution_channel_score\"})\n",
    "df = pd.merge(df,distribution_channel_df,how='left',on=['distribution_channel'])\n",
    "\n",
    "market_segment_df = pd.DataFrame(df[['is_canceled','market_segment']].groupby('market_segment', as_index=False).agg('mean'))\n",
    "market_segment_df = market_segment_df.rename(index=str, columns={\"is_canceled\": \"market_segment_score\"})\n",
    "df = pd.merge(df,market_segment_df,how='left',on=['market_segment'])  \n",
    "\n",
    "meal_df = pd.DataFrame(df[['is_canceled','meal']].groupby('meal', as_index=False).agg('mean'))\n",
    "meal_df = meal_df.rename(index=str, columns={\"is_canceled\": \"meal_score\"})\n",
    "df = pd.merge(df,meal_df,how='left',on=['meal'])\n",
    "\n",
    "deposit_type_df = pd.DataFrame(df[['is_canceled','deposit_type']].groupby('deposit_type', as_index=False).agg('mean'))\n",
    "deposit_type_df = deposit_type_df.rename(index=str, columns={\"is_canceled\": \"deposit_score\"})\n",
    "df = pd.merge(df,deposit_type_df,how='left',on=['deposit_type'])\n",
    "\n",
    "arrival_date_week_number_df = pd.DataFrame(df[['is_canceled','arrival_date_week_number']].groupby('arrival_date_week_number', as_index=False).agg('mean'))\n",
    "arrival_date_week_number_df = arrival_date_week_number_df.rename(index=str, columns={\"is_canceled\": \"week_number_score\"})\n",
    "df = pd.merge(df,arrival_date_week_number_df,how='left',on=['arrival_date_week_number']) \n",
    "\n",
    "#Addressing some outliers:\n",
    "df.lead_time = np.sqrt(np.sqrt(df.lead_time))\n",
    "df = df[df['required_car_parking_spaces']<2]\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "#Purging unneeded columns\n",
    "df_features = df[['is_canceled','agent_cancel_score','deposit_score','country_cancel_score','market_segment_score','lead_time','week_number_score','required_car_parking_spaces']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled                      int64\n",
       "agent_cancel_score             float64\n",
       "deposit_score                  float64\n",
       "country_cancel_score           float64\n",
       "market_segment_score           float64\n",
       "lead_time                      float64\n",
       "week_number_score              float64\n",
       "required_car_parking_spaces      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data \n",
    "X = df_features\n",
    "Y = df_features.is_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(1000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.720052\n",
       "1    0.279948\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp, X, Y, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
